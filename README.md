# ğŸ›’ AnÃ¡lise de Vendas de um Supermercado

Pipeline de Dados â€¢ Data Lake â€¢ Dashboards â€¢ ETL

## ğŸ“Œ VisÃ£o Geral

Este projeto foi desenvolvido para solucionar problemas de gerenciamento de dados enfrentados por um supermercado, que utilizava diversas planilhas e sistemas desconectados para armazenar informaÃ§Ãµes de vendas, produtos, categorias e estoques.

A soluÃ§Ã£o proposta consiste em um **pipeline completo de ingestÃ£o, processamento, armazenamento e anÃ¡lise**, permitindo gerar insights valiosos como:

* Produtos mais lucrativos
* AnÃ¡lises de sazonalidade
* PrevisÃµes e tendÃªncias de vendas
* Desempenho por categoria e produto
* HorÃ¡rios e dias de maior movimentaÃ§Ã£o

---

## ğŸ¯ Objetivos do Projeto

### **Objetivo Geral**

Construir um pipeline robusto para gestÃ£o e tratamento dos dados de vendas do supermercado.

### **Objetivos EspecÃ­ficos**

* Consolidar dados brutos em um **Data Lake estruturado**.
* Automatizar o processo de ingestÃ£o (batch ou streaming).
* Processar e limpar dados para anÃ¡lises confiÃ¡veis.
* Criar camadas de dados: **Raw, Bronze, Silver e Gold**.
* Gerar dashboards e KPIs acionÃ¡veis.
* Documentar arquitetura e decisÃµes tÃ©cnicas.

### **Justificativa TÃ©cnica**

A arquitetura adota boas prÃ¡ticas de engenharia de dados, garantindo:

* Escalabilidade do armazenamento
* Processamento eficiente (Spark ou Pandas)
* VisualizaÃ§Ã£o de alto nÃ­vel com dashboards
* Pipeline organizado por camadas
* Possibilidade de integraÃ§Ã£o futura com outros sistemas

---

## ğŸ§© Escopo da SoluÃ§Ã£o

### âœ”ï¸ **IncluÃ­do**

* IngestÃ£o de dados (CSV/JSON)
* Pipeline de processamento
* Data Lake em MinIO/S3
* Camadas: Raw, Bronze, Silver, Gold
* Dashboard com KPIs de vendas
* OrganizaÃ§Ã£o do repositÃ³rio
* DocumentaÃ§Ã£o completa

### âŒ **NÃ£o incluÃ­do**

* Modelos avanÃ§ados de previsÃ£o
* APIs externas
* Interface web
* IntegraÃ§Ã£o com ERP real

---

## ğŸ—ï¸ Arquitetura do Pipeline

O pipeline foi dividido em **4 etapas principais**:

### **1. IngestÃ£o**

* Leitura de arquivos CSV/JSON
* Upload automÃ¡tico para a camada **Raw**

### **2. Processamento**

* NormalizaÃ§Ã£o de colunas
* ConversÃ£o de tipos
* Tratamento de valores ausentes
* AgregaÃ§Ãµes (por produto, categoria, data, loja etc.)

### **3. Armazenamento**

* **Raw** â†’ dados brutos
* **Bronze** â†’ dados padronizados
* **Silver** â†’ dados limpos
* **Gold** â†’ dados analÃ­ticos prontos para dashboards

### **4. AnÃ¡lise**

* ConstruÃ§Ã£o de dashboards com:

  * Metabase
  * Superset
  * Power BI

---

## ğŸ› ï¸ Ferramentas e Tecnologias

* **Python (Pandas / PySpark)** â€“ processamento
* **MinIO / AWS S3** â€“ Data Lake
* **Docker Compose** â€“ infraestrutura
* **Jupyter Notebooks** â€“ exploraÃ§Ã£o
* **Superset / Metabase / Power BI** â€“ visualizaÃ§Ã£o
* **GitHub / Bitbucket** â€“ versionamento
* **Confluence** â€“ documentaÃ§Ã£o

---

## âš™ï¸ DecisÃµes TÃ©cnicas

### **Data Lake â†’ MinIO**

* Escolhido por simular S3 localmente
* Alternativa descartada: armazenamento local

### **Formato de Arquivos â†’ Parquet**

* Mais rÃ¡pido, compacto e eficiente
* CSV descartado por ser lento e ocupar mais espaÃ§o

### **Processamento â†’ Spark ou Pandas**

* Spark: ideal para grandes volumes
* Pandas: suficiente para datasets mÃ©dios

### **Dashboard â†’ Superset ou Power BI**

* Superset: ideal para ambiente tÃ©cnico
* Power BI: melhor para apresentaÃ§Ã£o comercial

---

## ğŸš€ Guia de ExecuÃ§Ã£o

### 1ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-repo/projeto-supermercado.git
```

### 2ï¸âƒ£ Subir os containers

```bash
docker-compose up -d
```

### 3ï¸âƒ£ Inserir arquivos brutos

Adicionar os arquivos na pasta:

```
/datasets/raw
```

### 4ï¸âƒ£ Executar o pipeline

```bash
python src/pipeline.py
```

### 5ï¸âƒ£ Visualizar dashboards

* Abrir Metabase ou Superset
* Conectar-se Ã  camada **Gold**
* Explorar KPIs e filtros

---

## ğŸ“¦ DependÃªncias

* Python â‰¥ 3.10
* Pandas â‰¥ 2.0
* PySpark (opcional)
* Docker â‰¥ 20.10
* docker-compose â‰¥ 1.29
* MinIO configurado
* Superset / Metabase

---

## ğŸ“Š DescriÃ§Ã£o dos Dados

### **Origem:**

SimulaÃ§Ã£o de vendas reais de supermercado.

### **Formato:**

Arquivos CSV ou JSON contendo vendas diÃ¡rias.

### ğŸ“ **Esquema Exemplo â€“ vendas**

| Campo        | Tipo     | DescriÃ§Ã£o                             |
| ------------ | -------- | ------------------------------------- |
| sale_id      | int      | ID da venda                           |
| date         | datetime | Data da venda                         |
| product_id   | int      | ID do produto                         |
| product_name | string   | Nome do produto                       |
| category     | string   | Categoria (frutas, bebidas, limpezaâ€¦) |
| unit_price   | float    | PreÃ§o unitÃ¡rio                        |
| quantity     | int      | Quantidade vendida                    |
| total        | float    | Valor total da venda                  |
| store        | string   | Unidade/loja                          |

---

## âš ï¸ LimitaÃ§Ãµes Conhecidas

* Dados podem conter inconsistÃªncias
* Arquivos muito grandes exigem Spark
* Dashboards dependem do Data Lake
* Crescimento do volume pode exigir Airflow
* NÃ£o hÃ¡ streaming real (Kafka)

---

## ğŸ‘©â€ğŸ’» Trabalho Individual

### **Antuane Felipe**

### **Gabrielle Palma**

* EstruturaÃ§Ã£o da documentaÃ§Ã£o no Confluence
* ConstruÃ§Ã£o da camada Silver
* ImplementaÃ§Ã£o da limpeza dos dados
* CriaÃ§Ã£o parcial do dashboard no Superset

### **Karolina Mendes**

### **VictÃ³ria Nascimento**